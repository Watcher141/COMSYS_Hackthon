{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f39191-feb7-4312-ab9c-451425a1ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9d9a93-5fdd-456c-b234-45ee749a7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "TRAIN_PATH = 'Task_A/train'\n",
    "VAL_PATH = 'Task_A/val'\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "EMBEDDING_DIM = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0fee376-3c66-43d0-97a1-e35e13a3fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MTCNN + FaceNet\n",
    "mtcnn = MTCNN(image_size=160, margin=20, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a7646e-170e-48c9-b8f8-89b28e8c17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Dataset\n",
    "class GenderFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.samples = []\n",
    "        self.label_map = {'male': 0, 'female': 1}  \n",
    "\n",
    "        for gender in ['male', 'female']:\n",
    "            gender_dir = os.path.join(root_dir, gender)\n",
    "            if not os.path.isdir(gender_dir):\n",
    "                continue\n",
    "            for fname in os.listdir(gender_dir):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append((os.path.join(gender_dir, fname), self.label_map[gender]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        face = mtcnn(img)\n",
    "        if face is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.samples))\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(face.unsqueeze(0).to(device)).squeeze(0).cpu()\n",
    "        return embedding, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca2454a7-6374-479f-813d-a40353898661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classifier \n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aeefe2f-ad71-494d-9512-55475aecfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loaders\n",
    "train_dataset = GenderFaceDataset(TRAIN_PATH)\n",
    "val_dataset = GenderFaceDataset(VAL_PATH)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a5f62bb-1fbe-4677-95bd-ee98b5760975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer \n",
    "model = BinaryClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b5ef355-8d6e-4e81-8062-f9753b67d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Early Stopping \n",
    "best_val_acc = 0\n",
    "patience = 3\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceb07384-69df-414a-8804-94f59b07509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [03:55<00:00,  1.95s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [01:00<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2592 | Train Acc: 89.30%\n",
      "Val   Loss: 0.3600 | Val   Acc: 90.05%\n",
      "Best model saved (Val Acc: 90.05%)\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [04:26<00:00,  2.20s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [01:05<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1484 | Train Acc: 94.81%\n",
      "Val   Loss: 0.3076 | Val   Acc: 91.47%\n",
      "Best model saved (Val Acc: 91.47%)\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [04:01<00:00,  2.00s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [01:05<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1195 | Train Acc: 95.48%\n",
      "Val   Loss: 0.2920 | Val   Acc: 91.00%\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [03:42<00:00,  1.84s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [00:52<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0989 | Train Acc: 96.52%\n",
      "Val   Loss: 0.3410 | Val   Acc: 91.71%\n",
      "Best model saved (Val Acc: 91.71%)\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [03:41<00:00,  1.83s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [00:59<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0891 | Train Acc: 96.88%\n",
      "Val   Loss: 0.3362 | Val   Acc: 92.18%\n",
      "Best model saved (Val Acc: 92.18%)\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [04:03<00:00,  2.01s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [01:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0741 | Train Acc: 97.56%\n",
      "Val   Loss: 0.3908 | Val   Acc: 91.00%\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [03:51<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [00:58<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0642 | Train Acc: 97.66%\n",
      "Val   Loss: 0.4061 | Val   Acc: 90.52%\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 121/121 [03:51<00:00,  1.92s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████| 27/27 [00:59<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0689 | Train Acc: 97.51%\n",
      "Val   Loss: 0.4037 | Val   Acc: 90.76%\n",
      "No improvement for 3 epoch(s)\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop \n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    for embeddings, labels in tqdm(train_loader, desc='Training'):\n",
    "        embeddings = embeddings.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  \n",
    "\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = (outputs > 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # ===== Validation =====\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in tqdm(val_loader, desc='Validation'):\n",
    "            embeddings = embeddings.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # ===== Early Stopping =====\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_binary_classifier.pth')\n",
    "        print(f\"Best model saved (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement for {counter} epoch(s)\")\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17bd84-a2ce-4966-80cb-03257273d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load face detector and embedding model\n",
    "mtcnn = MTCNN(image_size=160, margin=20, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Binary classifier model definition\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Load trained model\n",
    "model = BinaryClassifier().to(device)\n",
    "model.load_state_dict(torch.load('best_binary_classifier.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9db828-68f1-424f-a811-4cbc61d3850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Detect and crop face\n",
    "    face = mtcnn(img)\n",
    "    if face is None:\n",
    "        print(\"❌ No face detected.\")\n",
    "        return\n",
    "\n",
    "    # Generate embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = resnet(face.unsqueeze(0).to(device))\n",
    "        output = model(embedding)\n",
    "        prediction = (output > 0.5).float().item()\n",
    "\n",
    "    label = \"Female\" if prediction == 1 else \"Male\"\n",
    "    print(f\"✅ Predicted Gender: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f5555-1f33-4bcc-9828-0550d15e769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gender(\"Task_A/val/male/018_frontal.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01162b04-07f3-4746-a330-ce84ba74060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gender(\"Task_A/val/female/Jennifer_Keller_0001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62841380-2c32-44d7-97f5-aefb75024444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
